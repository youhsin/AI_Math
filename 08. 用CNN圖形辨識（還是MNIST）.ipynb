{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann LeCun 被譽為 Deep Learning 的三巨頭之一。他的 CNN (Convolutional Neural Networks) 是讓 Neural Network 重新受到重視的主因之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1 初始準備\n",
    "\n",
    "基本上和之前是一樣的, 我們就不再說明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-2 讀入 MNIST 數據庫\n",
    "\n",
    "### 由 Keras 讀入 MNIST\n",
    "\n",
    "基本上和我們上次一樣, 這次因為 Keras 已偷偷把數據庫存在你的電腦, 所以會快很多!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyouxin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入格式整理\n",
    "\n",
    "如果你還記得, 我們每筆輸入資料都是 28x28 的陣列, CNN 其實就是吃「圖」的, 所以基本上不用像之前把每筆資料拉平。「但。是。」平常的圖都有 R, G, B 三個 channels, 每個 channel 都是一個矩陣, 也就是一張圖可能是三個矩陣! 我們是灰階, 也就是只有一個 channel。但這件事也要明確的告訴 Keras。\n",
    "\n",
    "換句話說, 我們的輸入每筆資料型式要從 (28, 28) 換成 (28, 28, 1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 要的是 (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認一下..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原來 28x28 矩陣..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x107705c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X,  cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出格式整理\n",
    "\n",
    "和上次一樣, 我們用標準 1-hot 方式處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3 打造你的 CNN\n",
    "\n",
    "### 決定神經網路架構、讀入相關套件\n",
    "\n",
    "CNN 我們一樣要決定用幾層的 CNN, 然後是不是每次都要做 max-pooling。再來就是拉平、送入標準神經網路 (再度要決定幾層、幾個神經元)。\n",
    "\n",
    "我們上課的時候, 同學建議要做 3 次的 convolution + max-pooling, filter 大小都是 $5\\times 5$。\n",
    "\n",
    "* 做 <span style=\"color:red;\">3</span> 次 convolution, 每次都接 max-pooling\n",
    "* filter 大小都是 <span style=\"color:red;\">5x5</span>, max-pooling 都用 <span style=\"color:red;\">2x2</span> 為一小區塊\n",
    "\n",
    "CNN 一個小技巧是每層的 filters 數目是越來越多, 上課同學建議第一層 4 個, 因為要做三次, 所以我們 filters 數分別是 <span style=\"color:red;\">4, 8, 16</span>。做完 convolution 之後, 我們要拉平、再送入一個標準的神經網路。這個神經網路設計是這樣:\n",
    "\n",
    "* 只有 <span style=\"color:red;\">1</span> 個隱藏層, 使用 <span style=\"color:red;\">9</span> 個神經元 (這也是同學建議)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構我們的神經網路\n",
    "\n",
    "一開始一樣是打開個空白的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一個隱藏層一樣要告訴 Keras 我們輸入長什麼樣子。`padding` 設成 `same` 是每個 filter 會輸出原來 28x28 一樣大小的矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(4, (5, 5), padding='same', input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(8, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再 Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling 最終回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們要送進一般的神經網路了。記得這是要拉平的, 還在 Keras 會幫我們做!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(9))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出和上次一樣!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 組裝\n",
    "\n",
    "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=\"categorical_crossentropy\",\n",
    "#              optimizer=Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視我們的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 4)         104       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         808       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 16)          3216      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1305      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 5,533\n",
      "Trainable params: 5,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-4 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0090 - acc: 0.9418\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0084 - acc: 0.9455\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0079 - acc: 0.9489\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0075 - acc: 0.9513\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0072 - acc: 0.9537\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0068 - acc: 0.9558\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0066 - acc: 0.9575\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0063 - acc: 0.9594\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0061 - acc: 0.9607\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0059 - acc: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f471dc31a58>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡因為第一次訓練有點遜 (CNN 標準), 所以我再執行 `fit` 一次, 因此實際上是訓練了 20 次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8-5 結果測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分數\n",
    "\n",
    "我們來看測試資料 (我們的 CNN 沒看過的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 34us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看成績, 順便用 Python 3.6 開始的 f-string format 方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的 loss: 0.00578\n",
      "測試資料的正確率: 0.9621\n"
     ]
    }
   ],
   "source": [
    "print(f'測試資料的 loss: {score[0]:.5f}')\n",
    "print(f'測試資料的正確率: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 儲存結果\n",
    "\n",
    "結果看來還不差, 所以我們把結果存起來。上次我們介紹分別存架構和權重的方法, 這次我們看看怎麼樣一次就存入權重 + 結構!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 欣賞一下成果\n",
    "\n",
    "我們示範一下怎麼讀回我們的神經網路。你會發現讀回來之後就可以直接使用了!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把我們原來的 model 刪掉, 保證接下來的是讀進來的。我們要用一個 `load_model` 的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們用另一個方式: 每次選 5 個顯示, 看是不是有正確辨識。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看來真的可以直接用!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pick = np.random.randint(1,9999, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_test[pick[i]].reshape(28,28), cmap='Greys')\n",
    "    plt.title(predict[pick[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結論\n",
    "\n",
    "我們到此, 基本上是「亂做」的神經網路。有些同學在不斷試驗的過程中, 可能會發現有時會出現很糟糕的結果。因此, 接下來我們要介紹怎麼樣用些簡單的手法, 能讓學習效果比較穩定, 而且有可能可以增加學習效率。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
